{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN2ILKvjfEsg9OzdXKWlEj2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Navya2022/HealthBot/blob/main/Health_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U transformers datasets\n",
        "#import transformers\n",
        "#print(transformers.__version__)\n",
        "!pip install transformers==4.29.2 tokenizers==0.13.3 datasets==2.14.5 --no-build-isolation --no-cache-dir --upgrade\n",
        "\n",
        "\n",
        "\n",
        "import transformers\n",
        "import datasets\n",
        "\n",
        "print(\"Transformers version:\", transformers.__version__)\n",
        "print(\"Datasets version:\", datasets.__version__)\n",
        "\n"
      ],
      "metadata": {
        "id": "N_yvWrMxcr1D",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback,\n",
        ")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# Load and clean data\n",
        "df = pd.read_csv(\"Diseases_Symptoms.csv\")\n",
        "df = df.dropna(subset=[\"Symptoms\", \"Treatments\"])\n",
        "\n",
        "df[\"input\"] = \"symptoms = \" + df[\"Symptoms\"].str.lower()\n",
        "df[\"output\"] = \"prescription = \" + df[\"Treatments\"].str.lower()\n",
        "\n",
        "# Split into train and validation sets\n",
        "train_df, eval_df = train_test_split(df[[\"input\", \"output\"]], test_size=0.2, random_state=42)\n",
        "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
        "eval_dataset = Dataset.from_pandas(eval_df.reset_index(drop=True))\n",
        "\n",
        "# Load tokenizer and model\n",
        "model_name = \"t5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"./HealthBot\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./HealthBot\")\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_function(batch):\n",
        "    inputs = tokenizer(batch[\"input\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "    labels = tokenizer(batch[\"output\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "# Tokenize\n",
        "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_eval = eval_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./HealthBot\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=10,\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"loss\",\n",
        "    greater_is_better=False\n",
        ")\n",
        "\n",
        "# Trainer with early stopping\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        ")\n",
        "\n",
        "# Train\n",
        "trainer.train()\n",
        "\n",
        "# Save model\n",
        "model.save_pretrained(\"./HealthBot\")\n",
        "tokenizer.save_pretrained(\"./HealthBot\")"
      ],
      "metadata": {
        "id": "PoT8cdcgbSeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prescription(symptom_text):\n",
        "    input_text = \"symptoms: \" + symptom_text\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    output_ids = model.generate(\n",
        "        input_ids,\n",
        "        max_length=300,\n",
        "        num_beams=1,\n",
        "        do_sample=False,\n",
        "        repetition_penalty=10.0,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "Bja-qOHomgfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_prescription(\"nausea, headache,vomiting\"))"
      ],
      "metadata": {
        "id": "tKM0Pwzope0A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}